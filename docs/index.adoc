ifndef::leveloffset[]
:toc: left
:toclevels: 3
endif::[]

include::header.adoc[]

== Kubernetes

=== Resource types

* https://kubernetes.io/docs/reference/kubectl/#resource-types[Command line tool (kubectl) | Kubernetes^]

[source,shell]
----
kubectl api-resources
----

=== Config

[source,console]
----
$ kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://127.0.0.1:46829
  name: kind-kind-1
contexts:
- context:
    cluster: kind-kind-1
    user: kind-kind-1
  name: kind-kind-1
current-context: kind-kind-1
kind: Config
preferences: {}
users:
- name: kind-kind-1
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED
----

[source,console]
----
$ kubectl config get-contexts
CURRENT   NAME          CLUSTER       AUTHINFO      NAMESPACE
*         kind-kind-1   kind-kind-1   kind-kind-1
----

=== Secrets

* List secrets
+
[source,shell]
----
kubectl get secrets
----

* Show secrets

** Decode a specific secret
+
--
* Using `base64` command +
If the key contains dots, you must escape the dots with a backslash.
+
[source,shell]
----
kubectl get secrets/${SECRET_NAME} -o jsonpath='{.data.db\.conf}' | base64 -d
----
+
[source,shell]
----
kubectl get secrets/${SECRET_NAME} -o jsonpath="{.data['db\.conf']}" | base64 -d
----

* Using Go Template +
If your key contains hyphen symbols, you should use the index function.
+
[source,shell]
.Escape special characters in Go Template using index function
----
kubectl get secrets/${SECRET_NAME} -o go-template --template '{{"key-name: "}}{{ index .data "key-name" | base64decode }}{{ "\n" }}'
----
--
+
--
.References
* https://kubernetes.io/docs/reference/kubectl/jsonpath/[JSONPath Support | Kubernetes^]
* https://stackoverflow.com/questions/67186370/how-escape-chars-in-go-template[kubernetes - How escape chars in Go Template? - Stack Overflow^]
--

** Decode all secrets using jq
+
[source,shell]
----
kubectl get secrets name-of-secret -o json | jq '.data |= map_values(@base64d)'
----

** Decode all secrets using go-template
+
[source,shell]
----
kubectl get secret name-of-secret -o go-template='{{range $k,$v := .data}}{{printf "%s: " $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{"\n"}}{{end}}'
----
+
[source,console]
.Example
----
$ kubectl get secret postgres-client-sb -o go-template='{{range $k,$v := .data}}{{printf "%s: " $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{"\n"}}{{end}}'
database: fruits
host: postgres-service.postgres.svc.cluster.local
password: ************
port: 5432
type: postgresql
username: ************
----
+
--
.References
* https://stackoverflow.com/questions/56909180/decoding-kubernetes-secret[docker - Decoding Kubernetes secret - Stack Overflow^]
--

==== Examples
// include::../kind/secret-ex1/busybox.yaml[]
[source,yaml]
----
apiVersion: batch/v1
kind: Job
metadata:
  name: test-job
spec:
  template:
    spec:
      containers:
      - name: busybox-pod
        image: busybox
        command: ["cat", "/secret-ex1/fruits.txt"]
        volumeMounts:
        - mountPath: "/secret-ex1"
          name: secret-ex1
          readOnly: true
      restartPolicy: Never
      volumes:
      - name: secret-ex1
        secret:
          secretName: secret-ex1
  backoffLimit: 1
----

// include::../kind/secret-ex1/secret-ex1.sh[]
[source,shell]
----
#!/bin/bash
SCRIPT_PATH_IN=${BASH_SOURCE:-$0}
SCRIPT_NAME=$(basename ${SCRIPT_PATH_IN} .sh)
SCRIPT_DIR=$(dirname ${SCRIPT_PATH_IN})
WORK_DIR=$(mktemp -d -p /tmp ${SCRIPT_NAME}.XXXX)
trap 'rm -rf -- "${WORK_DIR}"' EXIT

usage() {
    cat 1>&2 <<EOF
usage: $0 {create|delete|show}
EOF
}

if [ $# -ne 1 ]; then
    usage
    exit 1
fi
CMD=$1
NAMESPACE="secret-ex1"
SECRET_NAME="secret-ex1"
JOB_NAME="test-job"

case $CMD in
create)
    (
     set -x;
     kubectl create ns ${NAMESPACE}
     printf "apple\nbanana\ncherry\n" > ${WORK_DIR}/fruits.txt
     kubectl create secret generic -n ${NAMESPACE} ${SECRET_NAME} --from-file=${WORK_DIR}/fruits.txt
     kubectl apply -f ${SCRIPT_DIR}/busybox.yaml -n ${NAMESPACE}
    )
    ;;

delete)
    (set -x; kubectl delete -f ${SCRIPT_DIR}/busybox.yaml -n ${NAMESPACE})
    (set -x; kubectl delete secret -n ${NAMESPACE} ${SECRET_NAME})
    (set -x; kubectl delete ns ${NAMESPACE})
    ;;

show)
    (set -x; kubectl get secret -n ${NAMESPACE} ${SECRET_NAME} -o jsonpath="{.data['fruits\.txt']}" | base64 -d)
    (set -x; kubectl get pods -n ${NAMESPACE})
    for POD_NAME in $(kubectl get pods -n "${NAMESPACE}" --output=jsonpath='{.items[*].metadata.name}'); do
        for CONTAINER_NAME in $(kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{.spec.containers[*].name}'); do
            (set -x; kubectl logs -n "${NAMESPACE}" "pod/${POD_NAME}" -c "${CONTAINER_NAME}")
        done
        for CONTAINER_NAME in $(kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{range .spec.initContainers[*]}{.name}{"\n"}{end}'); do
            (set -x; kubectl logs -n "${NAMESPACE}" "pod/${POD_NAME}" -c "${CONTAINER_NAME}")
        done
    done
    ;;

esac
----

.Results
* create secrets
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh create
+ kubectl create ns secret-ex1
namespace/secret-ex1 created
+ printf 'apple\nbanana\ncherry\n'
+ kubectl create secret generic -n secret-ex1 secret-ex1 --from-file=/tmp/secret-ex1.zdON/fruits.txt
secret/secret-ex1 created
+ kubectl apply -f kind/secret-ex1/busybox.yaml -n secret-ex1
job.batch/test-job created
----

* Show results
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh show
+ kubectl get secret -n secret-ex1 secret-ex1 -o 'jsonpath={.data['\''fruits\.txt'\'']}'
+ base64 -d
apple
banana
cherry
+ kubectl get pods -n secret-ex1
NAME             READY   STATUS      RESTARTS   AGE
test-job-xxxxx   0/1     Completed   0          6s
+ kubectl logs -n secret-ex1 test-job-xxxxx
apple
banana
cherry
----

* Delete secrets
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh delete
+ kubectl delete -f kind/secret-ex1/busybox.yaml -n secret-ex1
job.batch "test-job" deleted
+ kubectl delete secret -n secret-ex1 secret-ex1
secret "secret-ex1" deleted
+ kubectl delete ns secret-ex1
namespace "secret-ex1" deleted
----

* copying k8s secrets one namespace to another

** Using neat plugin
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | kubectl neat | sed -e 's/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----

** Using sed
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | grep -vE '(resourceVersion|uid):' | sed -e 's/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | sed -e '/\(resourceVersion\|uid\)/d; s/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----

** Examples

*** Setup
+
[source,shell]
----
kubectl create ns foo
kubectl create ns bar
kubectl create secret generic foo-secrets -n foo --from-literal=message="I'am foo"
----


*** List secrets
+
[source,shell]
----
kubectl get secrets -A
----

*** Show secrets
+
[source,shell]
----
kubectl get secret -n foo foo-secrets -o yaml -o jsonpath='{.data.message}' | base64 -d; echo
kubectl get secret -n bar foo-secrets -o yaml -o jsonpath='{.data.message}' | base64 -d; echo
----

*** Delete Resources
+
[source,shell]
----
kubectl delete -n bar foo-secrets
kubectl delete ns foo
kubectl delete ns bar
----

=== Namespace

* List namespaces
+
[source,console]
----
$ kubectl get namespace
NAME                 STATUS   AGE
default              Active   31h
kube-node-lease      Active   31h
kube-public          Active   31h
kube-system          Active   31h
local-path-storage   Active   31h
metallb-system       Active   8m8s
----

* Create/Apply namespace
+
[source,shell]
----
kubectl create ns "${NAMESPACE:-default}" --dry-run=client -o yaml | kubectl apply -f -
----

=== Nodes

[source,console]
----
$ kubectl get nodes --show-labels
NAME                   STATUS   ROLES           AGE   VERSION   LABELS
kind-1-control-plane   Ready    control-plane   45d   v1.24.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=kind-1-control-plane,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=
----

[source,shell]
----
kubectl get nodes kind-1-control-plane -o jsonpath="{.metadata.labels.kubernetes\.io/hostname}"
----

.References
* https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/[Assign Pods to Nodes | Kubernetes^]

=== Pods

* Get all pods
+
[source,shell]
----
kubectl get pods --all-namespaces
----

** Get pod names
+
[source,shell]
.Space separated list
----
kubectl -n "${NAMESPACE}" get pods --output=jsonpath='{.items[*].metadata.name}'
----
+
[source,shell]
.Newline separated list
----
kubectl -n "${NAMESPACE}" get pods --output=jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'
----

* Get labels
+
[source,shell]
----
kubectl get pods pod_name -o jsonpath="{.metadata.labels}" | python3 -m json.tool
----

* Wait pods
+
[source,shell]
----
kubectl wait -n metallb-system --for=condition=Ready pods --selector=app=metallb --timeout=90s
kubectl wait -n metallb-system --for=condition=Ready pods --selector=app=metallb -l component=controller --timeout=90s
kubectl wait -n metallb-system --for=condition=Ready pods --selector=app=metallb -l component=speaker --timeout=90s
----

=== ReplicaSets

* ReplicaSetオブジェクトに関する情報を表示します:
+
[source,console]
----
$ kubectl get replicasets
NAME                      DESIRED   CURRENT   READY   AGE
go-hello-app-54877bc7f9   0         0         0       9h
go-hello-app-6cf496f84c   1         1         1       28m
go-hello-app-854775f8d4   0         0         0       9h
----
+
[source,console]
----
$ kubectl describe replicasets
----

* Wait for ready
+
[source,shell]
----
kubectl wait -n metallb-system --for=jsonpath='{.status.readyReplicas}'=$(kubectl get -n metallb-system replicasets --selector=app=metallb -o jsonpath='{.items[0].spec.replicas}') replicasets --selector=app=metallb -l component=controller --timeout=90s
----
+
[source,console]
----
$ kubectl get replicasets -n metallb-system  -o yaml
apiVersion: v1
items:
- apiVersion: apps/v1
  kind: ReplicaSet
  metadata:
    annotations:
      deployment.kubernetes.io/desired-replicas: "1"
      deployment.kubernetes.io/max-replicas: "2"
      deployment.kubernetes.io/revision: "1"
    creationTimestamp: "2023-09-01T18:10:04Z"
    generation: 1
    labels:
      app: metallb
      component: controller
      pod-template-hash: 595f88d88f
    name: controller-595f88d88f
    namespace: metallb-system
  ...
  spec:
    replicas: 1
    selector:
      matchLabels:
        app: metallb
        component: controller
        pod-template-hash: 595f88d88f
    ...
  status:
    availableReplicas: 1
    fullyLabeledReplicas: 1
    observedGeneration: 1
    readyReplicas: 1
    replicas: 1
kind: List
metadata:
  resourceVersion: ""
$ kubectl wait -n metallb-system --for=jsonpath='{.status.readyReplicas}'=$(kubectl get -n metallb-system replicasets --selector=app=metallb -o jsonpath='{.items[0].spec.replicas}') replicasets --selector=app=metallb -l component=controller --timeout=90s
replicaset.apps/controller-595f88d88f condition met
----

=== Deployments

* Deploymentに関する情報を表示します:
+
[source,console]
----
$ kubectl get deployments go-hello-app
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
go-hello-app   1/1     1            1           9h
----
+
[source,console]
----
$ kubectl describe deployments go-hello-app
----

* Wait for Available
+
[source,shell]
----
kubectl wait -n metallb-system --for=condition=Available deployments --selector=app=metallb --timeout=90s
----
+
[cols="2" options="header,autowidth"]
.Conditions
|===
| Type            | Reason

h| Available      | MinimumReplicasAvailable
h| Progressing    | NewReplicaSetAvailable
h| ReplicaFailure | FailedCreate  
|===

* How to wait for a rollout to complete in Kubernetes
+
[source,shell]
----
kubectl rollout status deployment/controller -n metallb-system
----
+
[source,shell]
----
(set -x; kubectl rollout status deployment -n cert-manager -l app.kubernetes.io/component=controller --timeout=90s)
(set -x; kubectl rollout status deployment -n cert-manager -l app.kubernetes.io/component=cainjector --timeout=90s)
(set -x; kubectl rollout status deployment -n cert-manager -l app.kubernetes.io/component=webhook --timeout=90s)
----

* Delete deployment
+
[source,console]
----
$ kubectl delete deployment go-hello-app
----

==== Networking

* Get Pod IP's
+
[source,shell]
----
kubectl get pod go-hello-pod -o jsonpath='{.status.podIP}'
----
+
[source,console]
----
$ kubectl get pods -l app=go-hello-app -o custom-columns=POD_IP:.status.podIPs
POD_IP
[map[ip:10.244.0.12]]
[map[ip:10.244.0.13]]
----

* Accessing Pods through internal DNS with Pod IP
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" -it curl --image=curlimages/curl --rm --restart=Never --wait=true -- -s -L http://<pod-ip-address>.<service-name>.<namespace>.svc.cluster.local:8080/api/greet/John | python3 -m json.tool
----

* Port forwarding +
You can access the app inside WSL2 from your browser on your Windows host at http://localhost:8081/.
+
[source,shell]
----
kubectl port-forward -n demo --address=0.0.0.0 pod/greet-go-pod 8081:8080
----

.References
* https://kubernetes.io/docs/tasks/inject-data-application/_print/[Inject Data Into Applications | Kubernetes^] +
  kubernetes args dynamic pod ip - Google Search
* https://stackoverflow.com/questions/50248525/is-there-a-way-to-put-kubernetes-secret-value-in-args-field-of-yaml-file[Is there a way to put Kubernetes secret value in args field of yaml file - Stack Overflow^] +
  kubernetes args valueFrom - Google 検索
* https://stackoverflow.com/questions/51468491/how-kubectl-port-forward-works[kubernetes - How kubectl port-forward works? - Stack Overflow^] +
  kubectl port-forward --address=0.0.0.0 - Search

==== Container information

* Get container names

** Containers
+
[source,shell]
.Space separated list
----
kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{.spec.containers[*].name}'
----
+
[source,shell]
.Newline separated list
----
kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{range .spec.containers[*]}{.name}{"\n"}{end}'
----

** initContainers
+
[source,shell]
.Space separated list
----
kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{.spec.initContainers[*].name}'
----
+
[source,shell]
.Newline separated list
----
kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{range .spec.initContainers[*]}{.name}{"\n"}{end}'
----

* Get container ports

** Example 1
+
[source,shell]
----
kubectl get pods -l app=go-hello-app -o jsonpath='{.items[0].spec.containers[0].ports[0].containerPort}' | python3 -m json.tool
----
+
[source,console]
----
$ kubectl get pods -l app=go-hello-app -o custom-columns="Pod IP":.status.podIP,"Container port":.spec.containers[0].ports[].containerPort
Pod IP        Container port
10.244.0.12   8080
10.244.0.13   8080
----

** Example 2
+
[source,shell]
----
kubectl get -n demo pods -l app=greet-python-app -o jsonpath='{range .items[*]}{range .spec.containers[*]}{range .ports[*]}{.containerPort}{end}{" "}{end}{"\n"}{end}'
----
+
[source,console]
----
$ kubectl get -n demo pods -l app=greet-python-app -o jsonpath='{range .items[*]}{range .spec.containers[*]}{range .ports[*]}{.containerPort}{end}{" "}{end}{"\n"}{end}'
8080
----

** Example 3: Filter by container name
+
[source,shell]
----
kubectl get -n greet-go pod/${POD_NAME} -o jsonpath="{.spec.containers[?(@.name=='${CONTAINER_NAME}')].ports[0].containerPort}"
----


==== Run images

* Run curl images
+
[source,shell]
----
kubectl run -n "${NAMESPACE:-default}" -it curl --image=curlimages/curl --rm --restart=Never -- /bin/sh
----
https://hub.docker.com/r/curlimages/curl[curlimages/curl - Docker Image | Docker Hub^]

. Run docker image
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" -it --rm docker-in-docker --image=docker --restart=Never -- sh
----
https://hub.docker.com/_/docker[docker - Official Image | Docker Hub^] +
Docker in Docker!

* Run python images
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" -it python --image=python:3.8-slim-buster --rm --restart=Never -- python
----
https://hub.docker.com/_/python/[python - Official Image | Docker Hub^]

* Run nginx image +
https://hub.docker.com/_/nginx/[nginx - Official Image | Docker Hub^]
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" --image=nginx nginx -it --rm --restart=Never -- /bin/bash
----

** Patch: dnsPolicy: None and dnsConfig > nameservers > `8.8.8.8`
+
[source,shell]
----
kubectl run nginx -it --image=nginx --overrides='{ "apiVersion": "v1", "spec": { "dnsPolicy": "None", "dnsConfig": { "nameservers" : [ "8.8.8.8" ] } } }' --rm --restart=Never -- /bin/bash
----
+
[source,console]
----
root@nginx:/# cat /etc/resolv.conf 
nameserver 8.8.8.8
----

* Run ubuntu image
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" ubuntu -it --image=ubuntu:22.04 --rm --restart=Never -- /bin/bash
kubectl run -q -n "${NAMESPACE:-default}" ubuntu -it --image=ubuntu:latest --rm --restart=Never -- /bin/bash
kubectl run -q -n "${NAMESPACE:-default}" ubuntu -it --image=ubuntu:latest --rm --restart=Never --overrides='{ "apiVersion": "v1", "spec": { "dnsConfig": { "nameservers" : [ "8.8.8.8" ] } } }' -- /bin/bash
----

** `delv`, `dig`, `nslookup`, `nsupdate`, etc
+
[source,shell]
.Alias of `bind9-dnsutils`
----
apt update
apt-get install -y dnsutils
----
+
[source,shell]
.bind9-dnsutils
----
apt update
apt-get install -y bind9-dnsutils
----

** `ip`, `ss`, etc
+
[source,shell]
.iproute2
----
apt update
apt install -y iproute2
----

** `openssl`
+
[source,shell]
----
apt-get update
apt-get install -y openssl
----

==== Logs

[source,shell]
----
for POD_NAME in $(kubectl get pods -n "${NAMESPACE}" --output=jsonpath='{.items[*].metadata.name}'); do
    for CONTAINER_NAME in $(kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{.spec.containers[*].name}'); do
        (set -x; kubectl logs -n "${NAMESPACE}" "pod/${POD_NAME}" -c "${CONTAINER_NAME}")
    done
    for CONTAINER_NAME in $(kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{range .spec.initContainers[*]}{.name}{"\n"}{end}'); do
        (set -x; kubectl logs -n "${NAMESPACE}" "pod/${POD_NAME}" -c "${CONTAINER_NAME}")
    done
done
----

==== Using imagePullSecrets

* Attach secrets to pods
+
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: ${NAMESPACE}
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "https://ghcr.io": {
          "username": "${GITHUB_USERNAME}",
          "password": "${GITHUB_API_TOKEN}"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${SA_NAME}
  namespace: ${NAMESPACE}
---
apiVersion: v1
kind: Pod
metadata:
  name: greet-go-pod
  labels:
    app: greet-go-app
  namespace: ${NAMESPACE}
spec:
  serviceAccountName: ${SA_NAME}
  containers:
  - name: greet-go
    image: ghcr.io/********/greet-go:0.1
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 8080
  imagePullSecrets:
  - name: ghcr-secret
----

* Attach secrets to Service Account
+
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: ${NAMESPACE}
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "https://ghcr.io": {
          "username": "${GITHUB_USERNAME}",
          "password": "${GITHUB_API_TOKEN}"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${SA_NAME}
  namespace: ${NAMESPACE}
imagePullSecrets:
- name: ghcr-secret
---
apiVersion: v1
kind: Pod
metadata:
  name: greet-go-pod
  labels:
    app: greet-go-app
  namespace: ${NAMESPACE}
spec:
  serviceAccountName: ${SA_NAME}
  containers:
  - name: greet-go
    image: ghcr.io/********/greet-go:0.1
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 8080
----

=== Services

* Get Service in default namespace
+
[source,console]
----
$ kubectl get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   9h
----

** Get details
+
[source,shell]
----
kubectl get services go-hello-pod-metallb -o json | python3 -m json.tool
----

** Get external ip
+
[source,shell]
----
kubectl get services go-hello-pod-metallb -o jsonpath='{.status.loadBalancer.ingress[*].ip}'
----

** Get a port
+
[source,shell]
----
kubectl get services go-hello-service -o jsonpath='{.spec.ports[0].port}'
----

* Accessing Pods through internal DNS with Service Name
+
[source,shell]
----
kubectl run -q -n "${NAMESPACE:-default}" -it curl --image=curlimages/curl --rm --restart=Never --wait=true -- -s -L http://<service-name>.<namespace>.svc.cluster.local:3000/api/greet/John | python3 -m json.tool
----

* Delete service
+
[source,console]
----
$ kubectl delete services my-service
----

.Reference
* https://kubernetes.io/ja/docs/concepts/services-networking/dns-pod-service/[ServiceとPodに対するDNS | kubernetes.io](link:https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/[en])

=== CronJob

https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/[Running Automated Tasks with a CronJob | Kubernetes^]

* Shell
+
[source,yaml]
----
apiVersion: batch/v1
kind: CronJob
metadata:
  name: shell-cron-job
  labels:
    app: shell-cron-job
spec:
  schedule: "* * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: shell-cron-job
        spec:
          containers:
          - name: hello
            image: alpine:3.16
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
----

* Python
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: python-cron-job
  name: python-cron-job-src
  labels:
    app: python-cron-job
data:
  main.py: |
    #!env python
    import datetime
    import os
    import time
    try:
        import requests
    except ImportError:
        import subprocess
        import sys
        subprocess.run([
            sys.executable,
            "-m",
            "pip",
            "--disable-pip-version-check",
            "install",
            "requests"
        ])
        import requests


    def main():
        """main"""
        t_0: float
        t_1: float
        t_0 = time.time()
        usage_path_cpuacct = "/sys/fs/cgroup/cpuacct/cpuacct.usage"
        usage_path_memory = "/sys/fs/cgroup/memory/memory.usage_in_bytes"
        if os.path.isfile(usage_path_cpuacct):
            with open(usage_path_cpuacct) as file_handle:
                cpuacct_ns_t0 = int(file_handle.read())
        print(datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'))
        print("Hello from the Kubernetes cluster")
        res = requests.get("https://httpbin.org/get", params={
            "message": "Hello"
        })
        print(res.text)

        if os.path.isfile(usage_path_memory):
            with open(usage_path_memory) as file_handle:
                memory_usage_in_bytes = int(file_handle.read())
        if os.path.isfile(usage_path_cpuacct):
            with open(usage_path_cpuacct) as file_handle:
                cpuacct_ns_t1 = int(file_handle.read())
        t_1 = time.time()
        print(f"dt={t_1 - t_0:.2f}s {memory_usage_in_bytes/(1024*1024):.1f}MB {(cpuacct_ns_t1 - cpuacct_ns_t0)/1000000:.1f}ms")


    if __name__ == '__main__':
        main()
---
apiVersion: batch/v1
kind: CronJob
metadata:
  namespace: python-cron-job
  name: python-cron-job
  labels:
    app: python-cron-job
spec:
  schedule: "* * * * *"
  concurrencyPolicy: "Forbid"
  failedJobsHistoryLimit: 10
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          labels:
            app: python-cron-job
        spec:
          restartPolicy: Never
          containers:
          - name: default
            image: python:3.8-slim-buster
            imagePullPolicy: IfNotPresent
            command: ["python", "/app/main.py"]
            volumeMounts:
            - mountPath: "/app"
              name: app-volume
              readOnly: true
            resources:
              requests:
                cpu: "4m"
                memory: "64Mi"
              limits:
                cpu: "167m"
                memory: "128Mi"
          volumes:
          - name: app-volume
            configMap:
              name: python-cron-job-src
----

=== Endpoints

* Show all endpoints
+
[source,console]
----
$ kubectl get endpoints --all-namespaces
NAMESPACE        NAME                   ENDPOINTS                                               AGE
default          go-hello-pod-metallb   <none>                                                  5m36s
default          kubernetes             172.18.0.2:6443                                         37m
kube-system      kube-dns               10.244.0.2:53,10.244.0.3:53,10.244.0.2:53 + 3 more...   37m
metallb-system   webhook-service        10.244.0.5:9443                                         36m
----

* Get endpoints
+
[source,console]
----
kubectl get endpoints go-hello-service -o json
----
+
[source,json]
----
{
    "apiVersion": "v1",
    "kind": "Endpoints",
    "metadata": {
        "annotations": {
            "endpoints.kubernetes.io/last-change-trigger-time": "2022-08-27T23:57:09Z"
        },
        "creationTimestamp": "2022-08-27T23:57:07Z",
        "name": "go-hello-service",
        "namespace": "default",
        "resourceVersion": "14624",
        "uid": "9dbcd5ca-abd8-46a5-9ebd-aa91f7c99b59"
    },
    "subsets": [
        {
            "addresses": [
                {
                    "ip": "10.244.0.8",
                    "nodeName": "kind-1-control-plane",
                    "targetRef": {
                        "kind": "Pod",
                        "name": "go-hello-app-6cf496f84c-bq4rp",
                        "namespace": "default",
                        "uid": "16eb41f9-6f72-4438-ba0a-32cb83c603d5"
                    }
                }
            ],
            "ports": [
                {
                    "name": "http",
                    "port": 8080,
                    "protocol": "TCP"
                }
            ]
        }
    ]
}
----

* Describe endpoints
+
[source,console]
----
$ kubectl describe endpoints go-hello-service
Name:         go-hello-service
Namespace:    default
Labels:       <none>
Annotations:  endpoints.kubernetes.io/last-change-trigger-time: 2022-08-27T23:57:09Z
Subsets:
  Addresses:          10.244.0.8
  NotReadyAddresses:  <none>
  Ports:
    Name  Port  Protocol
    ----  ----  --------
    http  8080  TCP

Events:  <none>
----

=== Storage

==== emptyDir

// include::../kind/ex-storage-empty-dir.yaml[]
[source,yaml]
.kind/ex-storage-empty-dir.yaml
----
apiVersion: v1
kind: Pod
metadata:
  name: ex-storage-empty-dir
spec:
  containers:
  - image: nginx:1.23
    name: nginx-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
----

[source,shell]
----
kubectl apply -f kind/ex-storage-empty-dir.yaml
----

[source,console]
----
$ kubectl exec -it ex-storage-empty-dir -- df -h /cache
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdb        251G   17G  222G   8% /cache
----

==== Persistent Volume

[source,yaml]
----
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${PV_NAME}
spec:
  capacity:
    storage: 256Mi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: ""
  local:
    path: ${MOUNT_POINT}
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
            - ${KUBE_HOSTNAME}
----

// include::../kind/ex-storage-pv-local/ex-storage-pv-local-pod.yaml[]
[source,yaml]
.ex-storage-pv-local-pod.yaml
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-claim
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 128Mi
  storageClassName: ""
  volumeName: "ex-storage-pv"
  accessModes:
    - ReadWriteOnce
---
apiVersion: v1
kind: Pod
metadata:
  name: ex-storage-pv-local-pod
spec:
  nodeName: kind-1-control-plane
  containers:
  - image: nginx:1.23
    name: nginx-container
    imagePullPolicy: IfNotPresent
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    persistentVolumeClaim:
      claimName: local-claim
----

. Make directory (KIND only)
+
[source,shell]
----
docker exec ${KUBE_NODENAME} mkdir -p ${MOUNT_POINT}
----

. Deploy
+
[source,shell]
----
kubectl apply -f ${WORK_DIR}/ex-storage-pv-local.yaml
kubectl apply -f ex-storage-pv-local-pod.yaml
----

. Delete
+
[source,shell]
----
kubectl delete -f ex-storage-pv-local-pod.yaml
kubectl delete persistentvolume ${PV_NAME}
----

. Delete directory (KIND only)
+
[source,shell]
----
docker exec ${KUBE_NODENAME} rmdir ${MOUNT_POINT}
----

=== Get information

* List resource type short names
+
[source,shell]
----
kubectl api-resources
----

* Listing all resources in a namespace
+
[source,shell]
----
kubectl api-resources --verbs=list --namespaced -o name | python3 -c "import subprocess, sys; subprocess.run(['kubectl', 'get', '-n', '${NAMESPACE}', ','.join([x for x in sys.stdin.read().split() if x not in ['events.events.k8s.io', 'events']])])"
----
+
[source,shell]
----
kubectl api-resources --verbs=list --namespaced -o name | grep -vE '^(events|events\.events\.k8s\.io)$' | tr "\n" "," | sed -e 's/,$//' | xargs kubectl get -n "${NAMESPACE}"
----

* Filter by labels
+
[source,shell]
----
kubectl get -n "${NAMESPACE}" -l app=static-html-app cm,deploy,svc
----

* Filter by status

** List `Running` pods
+
[source,shell]
----
kubectl get -A --field-selector=status.phase=Running pods
----
+
[source,console]
----
$ kubectl get -A --field-selector=status.phase=Running pods
NAMESPACE               NAME                                                 READY   STATUS             RESTARTS       AGE
...
demo                    greet-python-pod                                     1/1     Running            6 (35m ago)    19d
...
static-html-k           static-html-app-7fdb5f6f56-hjn52                     0/1     ImagePullBackOff   1 (8h ago)     14d
----

** List `Failed` pods
+
[source,shell]
----
kubectl get -A --field-selector=status.phase=Failed pods
----
+
[source,console]
----
$ kubectl get -A --field-selector=status.phase=Failed pods
NAMESPACE   NAME     READY   STATUS    RESTARTS   AGE
default     curl     0/1     Unknown   0          21d
default     python   0/1     Unknown   0          21d
----

** List `Succeeded` pods
+
[source,shell]
----
kubectl get -A --field-selector=status.phase=Succeeded pods
----
+
[source,console]
----
$ kubectl get -A --field-selector=status.phase=Succeeded pods
NAMESPACE        NAME                            READY   STATUS      RESTARTS   AGE
projectcontour   contour-certgen-v1-26-0-rg8ng   0/1     Completed   0          49d
----


* Resource

** Show node usage
+
[source,console]
----
$ kubectl top node
NAME                   CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
kind-1-control-plane   366m         9%     53Mi            0%
----

** Show pod usage 1
+
[source,shell]
----
kubectl top pod -A
----

** Show pod usage 2
+
[source,shell]
----
kubectl get pod -n "${NAMESPACE}" -l app=${APP_NAME} --field-selector=status.phase=Running --output=jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' | while read POD_NAME; do
    for CONTAINER_NAME in $(kubectl -n "${NAMESPACE}" get pod/${POD_NAME} --output=jsonpath='{.spec.containers[*].name}'); do
        set -x
        MEM_BYTES=$(kubectl exec -n "${NAMESPACE}" "pod/${POD_NAME}" -c "${CONTAINER_NAME}" -- cat /sys/fs/cgroup/memory/memory.usage_in_bytes)
        set +x
        python3 -c "print(f\"{${MEM_BYTES}/(1024*1024):.1f} MB\")"
    done
done
----

** Get metrics
+
[source,console]
----
$ kubectl describe PodMetrics -n python-cron-job
Name:         python-cron-job-28020409-27rc6
Namespace:    python-cron-job
Labels:       app=python-cron-job
              controller-uid=c01968bb-929d-428e-82dd-3845251b9587
              job-name=python-cron-job-28020409
Annotations:  <none>
API Version:  metrics.k8s.io/v1beta1
Containers:
  Name:  default
  Usage:
    Cpu:     54408n
    Memory:  47048Ki
Kind:        PodMetrics
Metadata:
  Creation Timestamp:  2023-04-11T14:51:01Z
Timestamp:             2023-04-11T14:50:34Z
Window:                10.173s
Events:                <none>
----

=== Troubleshooting

* ip route
+
[source,console]
----
$ ip route
default via 172.31.160.1 dev eth0
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
172.18.0.0/16 dev br-cb34625844b6 proto kernel scope link src 172.18.0.1
172.31.160.0/20 dev eth0 proto kernel scope link src 172.31.169.105
----

** Show a specific route
+
[source,console]
----
$ ip route list 172.18.0.0/16
172.18.0.0/16 dev br-cb34625844b6 proto kernel scope link src 172.18.0.1
----

* arp +
Service に対する Endpoint が作成されていない場合は、 `HWaddress` の項目は `(incomplete)` になる
+
[source,console]
----
$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
172.18.0.2               ether   02:42:ac:12:00:02   C                     br-cb34625844b6
DESKTOP-E39V4F4          ether   00:15:5d:31:24:02   C                     eth0
172.18.254.240                   (incomplete)                              br-cb34625844b6
----

* arping
+
[source,console]
----
$ sudo arping 172.18.254.240 -c 3
ARPING 172.18.254.240
Timeout
Timeout
Timeout

--- 172.18.254.240 statistics ---
3 packets transmitted, 0 packets received, 100% unanswered (0 extra)
----

* Find ip
+
[source,console]
----
$ kubectl get services --all-namespaces | grep 172.18.254
default          go-hello-pod-metallb   LoadBalancer   10.96.17.114    172.18.254.240   8080:30161/TCP           22m
----

=== Auth

[source,shell]
----
kubectl auth can-i list pods
----

=== API

* List API resources
+
[source,shell]
----
kubectl api-resources
----

* Get API Server URI
+
[source,shell]
----
kubectl config view -o jsonpath='{.clusters[0].cluster.server}'
----

* Get version
+
[source,shell]
----
curl --insecure $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/version
----

* Using client certificate
+
[source,shell]
----
kubectl config view --minify --raw -o jsonpath='{.users[].user.client-certificate-data}' | base64 --decode > client.crt
kubectl config view --minify --raw -o jsonpath='{.users[].user.client-key-data}' | base64 --decode > client.key
----

** List apis
+
[source,shell]
----
curl --insecure --cert ./client.crt --key ./client.key $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/apis
----

** List pod name
+
[source,shell]
----
curl -s --insecure --cert ./client.crt --key ./client.key $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/api/v1/namespaces/rbac-demo/pods | jq -r '.items[] | .metadata.name'
----

== Service Binding

.Setup Service Binding
. Install `cert-manager`
+
[source,shell]
----
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yaml
----
+
.References
* https://cert-manager.io/docs/installation/[Installation - cert-manager Documentation^]

. To install the Service Binding Runtime with kubectl, run:
+
[source,shell]
----
kubectl apply -f https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml
----
+
.References
* https://github.com/servicebinding/runtime/releases[Releases · servicebinding/runtime^]

.References
* https://github.com/spring-cloud/spring-cloud-bindings[spring-cloud/spring-cloud-bindings^] +
  A library that exposes a rich Java language-binding and auto-configuration for CNB Bindings

=== Service binding installation fails during ContainerCreating

[source,console]
----
...
+ kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.12.0/cert-manager.yaml
namespace/cert-manager created
...
validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created
+ true
++ kubectl get pods -n cert-manager -l app.kubernetes.io/component=webhook
+ '[' -n 'NAME                                    READY   STATUS              RESTARTS   AGE
cert-manager-webhook-5655dcfb4b-xxxxx   0/1     ContainerCreating   0          1s' ']'
+ break
+ set -x
+ kubectl wait pods -n cert-manager -l app.kubernetes.io/component=webhook --for condition=Ready --timeout=90s
pod/cert-manager-webhook-5655dcfb4b-xxxxx condition met
+ set -x
+ kubectl get deployment.apps -n cert-manager
NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
cert-manager              0/1     1            0           16s
cert-manager-cainjector   0/1     1            0           16s
cert-manager-webhook      1/1     1            1           16s
+ set -x
+ kubectl get pods -n cert-manager
NAME                                      READY   STATUS              RESTARTS   AGE
cert-manager-7476c8fcf4-xc2l9             0/1     ContainerCreating   0          16s
cert-manager-cainjector-bdd866bd4-8v8nw   0/1     ContainerCreating   0          16s
cert-manager-webhook-5655dcfb4b-xxxxx     1/1     Running             0          16s
+ set -x
+ kubectl rollout status deployment -n cert-manager -l component=controller --timeout=90s
+ set -x
+ kubectl rollout status deployment -n cert-manager -l component=webhook --timeout=90s
+ : Install Service Binding
+ set -x
+ kubectl apply -f https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml
namespace/servicebinding-system created
...
validatingwebhookconfiguration.admissionregistration.k8s.io/servicebinding-trigger created
validatingwebhookconfiguration.admissionregistration.k8s.io/servicebinding-validating-webhook-configuration created
Error from server (InternalError): error when creating "https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml": Internal error occurred: failed calling webhook "webhook.cert-manager.io": failed to call webhook: Post "https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=10s": tls: failed to verify certificate: x509: certificate signed by unknown authority
Error from server (InternalError): error when creating "https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml": Internal error occurred: failed calling webhook "webhook.cert-manager.io": failed to call webhook: Post "https://cert-manager-webhook.cert-manager.svc:443/mutate?timeout=10s": tls: failed to verify certificate: x509: certificate signed by unknown authority
----

[source,console]
----
$ (set -x; kubectl rollout status deployment -n cert-manager -l component=controller --timeout=90s)
+ kubectl rollout status deployment -n cert-manager -l component=controller --timeout=90s
guest@ubuntu22-wsl:~/tmp_github/kubernetes-examples/kind$ kubectl get all -n cert-manager
NAME                                          READY   STATUS    RESTARTS   AGE
pod/cert-manager-7476c8fcf4-xc2l9             1/1     Running   0          4m5s
pod/cert-manager-cainjector-bdd866bd4-8v8nw   1/1     Running   0          4m5s
pod/cert-manager-webhook-5655dcfb4b-xxxxx     1/1     Running   0          4m5s

NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE
service/cert-manager           ClusterIP   10.96.249.221   <none>        9402/TCP   4m5s
service/cert-manager-webhook   ClusterIP   10.96.155.89    <none>        443/TCP    4m5s

NAME                                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/cert-manager              1/1     1            1           4m5s
deployment.apps/cert-manager-cainjector   1/1     1            1           4m5s
deployment.apps/cert-manager-webhook      1/1     1            1           4m5s

NAME                                                DESIRED   CURRENT   READY   AGE
replicaset.apps/cert-manager-7476c8fcf4             1         1         1       4m5s
replicaset.apps/cert-manager-cainjector-bdd866bd4   1         1         1       4m5s
replicaset.apps/cert-manager-webhook-5655dcfb4b     1         1         1       4m5s
----

[source,console]
----
$ (set -x; kubectl apply -f https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml)
+ kubectl apply -f https://github.com/servicebinding/runtime/releases/download/v0.4.0/servicebinding-runtime-v0.4.0.yaml
namespace/servicebinding-system unchanged
...
configmap/servicebinding-manager-config unchanged
service/servicebinding-controller-manager-metrics-service unchanged
service/servicebinding-webhook-service unchanged
deployment.apps/servicebinding-controller-manager unchanged
certificate.cert-manager.io/servicebinding-serving-cert created
issuer.cert-manager.io/servicebinding-selfsigned-issuer created
mutatingwebhookconfiguration.admissionregistration.k8s.io/servicebinding-admission-projector unchanged
validatingwebhookconfiguration.admissionregistration.k8s.io/servicebinding-trigger unchanged
validatingwebhookconfiguration.admissionregistration.k8s.io/servicebinding-validating-webhook-configuration configured
----

== Install kubectl

.References
* https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/[Install and Set Up kubectl on Linux | Kubernetes^]
* https://kubernetes.io/ja/docs/tasks/tools/install-kubectl/[kubectlのインストールおよびセットアップ | Kubernetes^]

=== Install kubectl binary with curl on Linux

. Download latest version.
+
[source,shell]
----
curl -LO "https://dl.k8s.io/release/$(curl -LS https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
install -m 755 kubectl $HOME/bin/
rm kubectl
----

. Add bash completion
+
[source,shell]
----
kubectl completion bash | sudo tee /etc/bash_completion.d/kubectl > /dev/null
exec $SHELL -l
----

=== Install kubectl using apt package manager

. Update the `apt` package index and install packages needed to use the Kubernetes `apt` repository:
+
[source,shell]
----
sudo apt-get update
sudo apt-get install -y ca-certificates curl
----

. Download the Google Cloud public signing key:
+
[source,shell]
----
sudo install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-archive-keyring.gpg
sudo chmod a+r /etc/apt/keyrings/kubernetes-archive-keyring.gpg
----

. Add the Kubernetes `apt` repository:
+
[source,shell]
----
echo "deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list > /dev/null
----

. Update apt package index with the new repository and install kubectl:
+
[source,shell]
----
sudo apt-get update
sudo apt-get install -y kubectl
----

== krew

=== Install krew

https://krew.sigs.k8s.io/docs/user-guide/setup/install/[Installing · Krew^]

.Install
. Run this command to download and install krew:
+
[source,shell]
----
(
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
----

. Add the $HOME/.krew/bin directory to your PATH environment variable.
+
[source,shell]
.~/.bashrc
----
test -d ${KREW_ROOT:-$HOME/.krew} && export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"
----

. Run kubectl krew to check the installation.
+
[source,shell]
----
kubectl krew version
----

. Install plug-ins
+
[source,shell]
----
kubectl krew install neat
----

== Knative

* https://qiita.com/t_okkan/items/eef036534ce3d5511df6[Knative Servingでサーバーレスを始める - Qiita^] +
  Knative - Search

== References
