ifndef::leveloffset[]
:toc: left
:toclevels: 3
endif::[]

include::header.adoc[]

== Kubernetes

=== Config

[source,console]
----
$ kubectl config view
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: DATA+OMITTED
    server: https://127.0.0.1:46829
  name: kind-kind-1
contexts:
- context:
    cluster: kind-kind-1
    user: kind-kind-1
  name: kind-kind-1
current-context: kind-kind-1
kind: Config
preferences: {}
users:
- name: kind-kind-1
  user:
    client-certificate-data: REDACTED
    client-key-data: REDACTED
----

[source,console]
----
$ kubectl config get-contexts
CURRENT   NAME          CLUSTER       AUTHINFO      NAMESPACE
*         kind-kind-1   kind-kind-1   kind-kind-1
----

=== Secrets

* List secrets
+
[source,shell]
----
kubectl get secrets
----

* Show secrets

** Decode a specific secret
+
--
* Using `base64` command +
If the key contains dots, you must escape the dots with a backslash.
+
[source,shell]
----
kubectl get secrets/${SECRET_NAME} -o jsonpath='{.data.db\.conf}' | base64 -d
----
+
[source,shell]
----
kubectl get secrets/${SECRET_NAME} -o jsonpath="{.data['db\.conf']}" | base64 -d
----

* Using Go Template +
If your key contains hyphen symbols, you should use the index function.
+
[source,shell]
.Escape special characters in Go Template using index function
----
kubectl get secrets/${SECRET_NAME} -o go-template --template '{{"key-name: "}}{{ index .data "key-name" | base64decode }}{{ "\n" }}'
----
--
+
--
.References
* https://kubernetes.io/docs/reference/kubectl/jsonpath/[JSONPath Support | Kubernetes^]
* https://stackoverflow.com/questions/67186370/how-escape-chars-in-go-template[kubernetes - How escape chars in Go Template? - Stack Overflow^]
--

** Decode all secrets using jq
+
[source,shell]
----
kubectl get secrets name-of-secret -o json | jq '.data |= map_values(@base64d)'
----

** Decode all secrets using go-template
+
[source,shell]
----
kubectl get secret name-of-secret -o go-template='{{range $k,$v := .data}}{{printf "%s: " $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{"\n"}}{{end}}'
----
+
[source,console]
.Example
----
$ kubectl get secret postgres-client-sb -o go-template='{{range $k,$v := .data}}{{printf "%s: " $k}}{{if not $v}}{{$v}}{{else}}{{$v | base64decode}}{{end}}{{"\n"}}{{end}}'
database: fruits
host: postgres-service.postgres.svc.cluster.local
password: ************
port: 5432
type: postgresql
username: ************
----
+
--
.References
* https://stackoverflow.com/questions/56909180/decoding-kubernetes-secret[docker - Decoding Kubernetes secret - Stack Overflow^]
--

==== Examples
// include::../kind/secret-ex1/busybox.yaml[]
[source,yaml]
----
apiVersion: batch/v1
kind: Job
metadata:
  name: test-job
spec:
  template:
    spec:
      containers:
      - name: busybox-pod
        image: busybox
        command: ["cat", "/secret-ex1/fruits.txt"]
        volumeMounts:
        - mountPath: "/secret-ex1"
          name: secret-ex1
          readOnly: true
      restartPolicy: Never
      volumes:
      - name: secret-ex1
        secret:
          secretName: secret-ex1
  backoffLimit: 1
----

// include::../kind/secret-ex1/secret-ex1.sh[]
[source,shell]
----
#!/bin/bash
SCRIPT_PATH_IN=${BASH_SOURCE:-$0}
SCRIPT_NAME=$(basename ${SCRIPT_PATH_IN} .sh)
SCRIPT_DIR=$(dirname ${SCRIPT_PATH_IN})
WORK_DIR=$(mktemp -d -p /tmp ${SCRIPT_NAME}.XXXX)
trap 'rm -rf -- "${WORK_DIR}"' EXIT

usage() {
    cat 1>&2 <<EOF
usage: $0 {create|delete|show}
EOF
}

if [ $# -ne 1 ]; then
    usage
    exit 1
fi
CMD=$1
NAMESPACE="secret-ex1"
SECRET_NAME="secret-ex1"
JOB_NAME="test-job"

case $CMD in
create)
    (
     set -x;
     kubectl create ns ${NAMESPACE}
     printf "apple\nbanana\ncherry\n" > ${WORK_DIR}/fruits.txt
     kubectl create secret generic -n ${NAMESPACE} ${SECRET_NAME} --from-file=${WORK_DIR}/fruits.txt
     kubectl apply -f ${SCRIPT_DIR}/busybox.yaml -n ${NAMESPACE}
    )
    ;;

delete)
    (set -x; kubectl delete -f ${SCRIPT_DIR}/busybox.yaml -n ${NAMESPACE})
    (set -x; kubectl delete secret -n ${NAMESPACE} ${SECRET_NAME})
    (set -x; kubectl delete ns ${NAMESPACE})
    ;;

show)
    (set -x; kubectl get secret -n ${NAMESPACE} ${SECRET_NAME} -o jsonpath="{.data['fruits\.txt']}" | base64 -d)
    (set -x; kubectl get pods -n ${NAMESPACE})
    kubectl get pods --selector=job-name=${JOB_NAME} --output=jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}' -n ${NAMESPACE} | while read POD_NAME; do
        (set -x; kubectl logs -n ${NAMESPACE} ${POD_NAME})
    done
    ;;

esac
----

.Results
* create secrets
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh create
+ kubectl create ns secret-ex1
namespace/secret-ex1 created
+ printf 'apple\nbanana\ncherry\n'
+ kubectl create secret generic -n secret-ex1 secret-ex1 --from-file=/tmp/secret-ex1.zdON/fruits.txt
secret/secret-ex1 created
+ kubectl apply -f kind/secret-ex1/busybox.yaml -n secret-ex1
job.batch/test-job created
----

* Show results
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh show
+ kubectl get secret -n secret-ex1 secret-ex1 -o 'jsonpath={.data['\''fruits\.txt'\'']}'
+ base64 -d
apple
banana
cherry
+ kubectl get pods -n secret-ex1
NAME             READY   STATUS      RESTARTS   AGE
test-job-xxxxx   0/1     Completed   0          6s
+ kubectl logs -n secret-ex1 test-job-xxxxx
apple
banana
cherry
----

* Delete secrets
+
[source,console]
----
$ kind/secret-ex1/secret-ex1.sh delete
+ kubectl delete -f kind/secret-ex1/busybox.yaml -n secret-ex1
job.batch "test-job" deleted
+ kubectl delete secret -n secret-ex1 secret-ex1
secret "secret-ex1" deleted
+ kubectl delete ns secret-ex1
namespace "secret-ex1" deleted
----

* copying k8s secrets one namespace to another

** Using neat plugin
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | kubectl neat | sed -e 's/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----

** Using sed
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | grep -vE '(resourceVersion|uid):' | sed -e 's/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----
+
[source,shell]
----
kubectl get secrets foo-secrets -n foo -o yaml | sed -e '/\(resourceVersion\|uid\)/d; s/\(namespace:\) foo/\1 bar/' | kubectl apply -n bar -f -
----

** Examples

*** Setup
+
[source,shell]
----
kubectl create ns foo
kubectl create ns bar
kubectl create secret generic foo-secrets -n foo --from-literal=message="I'am foo"
----


*** List secrets
+
[source,shell]
----
kubectl get secrets -A
----

*** Show secrets
+
[source,shell]
----
kubectl get secret -n foo foo-secrets -o yaml -o jsonpath='{.data.message}' | base64 -d; echo
kubectl get secret -n bar foo-secrets -o yaml -o jsonpath='{.data.message}' | base64 -d; echo
----

*** Delete Resources
+
[source,shell]
----
kubectl delete -n bar foo-secrets
kubectl delete ns foo
kubectl delete ns bar
----

=== Namespace

[source,console]
----
$ kubectl get namespace
NAME                 STATUS   AGE
default              Active   31h
kube-node-lease      Active   31h
kube-public          Active   31h
kube-system          Active   31h
local-path-storage   Active   31h
metallb-system       Active   8m8s
----

=== Nodes

[source,console]
----
$ kubectl get nodes --show-labels
NAME                   STATUS   ROLES           AGE   VERSION   LABELS
kind-1-control-plane   Ready    control-plane   45d   v1.24.0   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/hostname=kind-1-control-plane,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node.kubernetes.io/exclude-from-external-load-balancers=
----

[source,shell]
----
kubectl get nodes kind-1-control-plane -o jsonpath="{.metadata.labels.kubernetes\.io/hostname}"
----

.References
* https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/[Assign Pods to Nodes | Kubernetes^]

=== Deployments

* Deploymentに関する情報を表示します:
+
[source,console]
----
$ kubectl get deployments go-hello-app
NAME           READY   UP-TO-DATE   AVAILABLE   AGE
go-hello-app   1/1     1            1           9h
----
+
[source,console]
----
$ kubectl describe deployments go-hello-app
----

* Delete deployment
+
[source,console]
----
$ kubectl delete deployment go-hello-app
----

=== Pods

* Get all pods
+
[source,shell]
----
kubectl get pods --all-namespaces
----

* Get labels
+
[source,shell]
----
kubectl get pods pod_name -o jsonpath="{.metadata.labels}" | python3 -m json.tool
----

* Wait pods
+
[source,shell]
----
kubectl wait pods -n metallb-system -l component=controller --for condition=Ready --timeout=90s
----

* Get Pod IP's
+
[source,shell]
----
kubectl get pod go-hello-pod -o jsonpath='{.status.podIP}'
----
+
[source,console]
----
$ kubectl get pods -l app=go-hello-app -o custom-columns=POD_IP:.status.podIPs
POD_IP
[map[ip:10.244.0.12]]
[map[ip:10.244.0.13]]
----

* Get container ports
+
[source,shell]
----
kubectl get pods -l app=go-hello-app -o jsonpath='{.items[0].spec.containers[0].ports[0].containerPort}' | python3 -m json.tool
----
+
[source,console]
----
$ kubectl get pods -l app=go-hello-app -o custom-columns="Pod IP":.status.podIP,"Container port":.spec.containers[0].ports[].containerPort
Pod IP        Container port
10.244.0.12   8080
10.244.0.13   8080
----

* Accessing Pods through internal DNS with Pod IP
+
[source,shell]
----
kubectl run -q -n default -it curl --image=curlimages/curl --rm --restart=Never --wait=true -- -s -L http://<pod-ip-address>.<service-name>.<namespace>.svc.cluster.local:8080/api/greet/John | python3 -m json.tool
----

* Add curl images
+
[source,shell]
----
kubectl run -n default -it curl --image=curlimages/curl --rm --restart=Never -- /bin/sh
----
+
* https://hub.docker.com/r/curlimages/curl[curlimages/curl - Docker Image | Docker Hub^]

.References
* https://kubernetes.io/docs/tasks/inject-data-application/_print/[Inject Data Into Applications | Kubernetes^] +
  kubernetes args dynamic pod ip - Google Search
* https://stackoverflow.com/questions/50248525/is-there-a-way-to-put-kubernetes-secret-value-in-args-field-of-yaml-file[Is there a way to put Kubernetes secret value in args field of yaml file - Stack Overflow^] +
  kubernetes args valueFrom - Google 検索

==== Using imagePullSecrets

* Attach secrets to pods
+
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: ${NAMESPACE}
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "https://ghcr.io": {
          "username": "${GITHUB_USERNAME}",
          "password": "${GITHUB_API_TOKEN}"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${SA_NAME}
  namespace: ${NAMESPACE}
---
apiVersion: v1
kind: Pod
metadata:
  name: greet-go-pod
  labels:
    app: greet-go-app
  namespace: ${NAMESPACE}
spec:
  serviceAccountName: ${SA_NAME}
  containers:
  - name: greet-go
    image: ghcr.io/unmyr/greet-go:0.1
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 8080
  imagePullSecrets:
  - name: ghcr-secret
----

* Attach secrets to Service Account
+
[source,yaml]
----
apiVersion: v1
kind: Namespace
metadata:
  name: ${NAMESPACE}
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: ${NAMESPACE}
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "https://ghcr.io": {
          "username": "${GITHUB_USERNAME}",
          "password": "${GITHUB_API_TOKEN}"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ${SA_NAME}
  namespace: ${NAMESPACE}
imagePullSecrets:
- name: ghcr-secret
---
apiVersion: v1
kind: Pod
metadata:
  name: greet-go-pod
  labels:
    app: greet-go-app
  namespace: ${NAMESPACE}
spec:
  serviceAccountName: ${SA_NAME}
  containers:
  - name: greet-go
    image: ghcr.io/unmyr/greet-go:0.1
    imagePullPolicy: IfNotPresent
    ports:
    - containerPort: 8080
----

=== ReplicaSets

* ReplicaSetオブジェクトに関する情報を表示します:
+
[source,console]
----
$ kubectl get replicasets
NAME                      DESIRED   CURRENT   READY   AGE
go-hello-app-54877bc7f9   0         0         0       9h
go-hello-app-6cf496f84c   1         1         1       28m
go-hello-app-854775f8d4   0         0         0       9h
----
+
[source,console]
----
$ kubectl describe replicasets
----

=== Services

* Get Service in default namespace
+
[source,console]
----
$ kubectl get services
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   9h
----

** Get details
+
[source,shell]
----
kubectl get services go-hello-pod-metallb -o json | python3 -m json.tool
----

** Get external ip
+
[source,shell]
----
kubectl get services go-hello-pod-metallb -o jsonpath='{.status.loadBalancer.ingress[*].ip}'
----

** Get a port
+
[source,shell]
----
kubectl get services go-hello-service -o jsonpath='{.spec.ports[0].port}'
----

* Accessing Pods through internal DNS with Service Name
+
[source,shell]
----
kubectl run -q -n default -it curl --image=curlimages/curl --rm --restart=Never --wait=true -- -s -L http://<service-name>.<namespace>.svc.cluster.local:3000/api/greet/John | python3 -m json.tool
----

* Delete service
+
[source,console]
----
$ kubectl delete services my-service
----

.Reference
* https://kubernetes.io/ja/docs/concepts/services-networking/dns-pod-service/[ServiceとPodに対するDNS | kubernetes.io](link:https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/[en])

=== CronJob

https://kubernetes.io/docs/tasks/job/automated-tasks-with-cron-jobs/[Running Automated Tasks with a CronJob | Kubernetes^]

* Shell
+
[source,yaml]
----
apiVersion: batch/v1
kind: CronJob
metadata:
  name: shell-cron-job
  labels:
    app: shell-cron-job
spec:
  schedule: "* * * * *"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: shell-cron-job
        spec:
          containers:
          - name: hello
            image: alpine:3.16
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
----

* Python
+
[source,yaml]
----
apiVersion: v1
kind: ConfigMap
metadata:
  namespace: python-cron-job
  name: python-cron-job-main
  labels:
    app: python-cron-job
data:
  main.py: |
    #!env python
    import datetime


    def main():
        """main"""
        print(datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'))
        print("Hello from the Kubernetes cluster")


    if __name__ == '__main__':
        main()
---
apiVersion: batch/v1
kind: CronJob
metadata:
  namespace: python-cron-job
  name: python-cron-job
  labels:
    app: python-cron-job
spec:
  schedule: "* * * * *"
  concurrencyPolicy: "Forbid"
  failedJobsHistoryLimit: 10
  jobTemplate:
    spec:
      backoffLimit: 0
      template:
        metadata:
          labels:
            app: python-cron-job
        spec:
          restartPolicy: Never
          containers:
          - name: default
            image: python:3.8-slim-buster
            imagePullPolicy: IfNotPresent
            command: ["python", "/app/main.py"]
            volumeMounts:
            - mountPath: "/app"
              name: app-volume
              readOnly: true
          volumes:
          - name: app-volume
            configMap:
              name: python-cron-job-main
----

=== Endpoints

* Show all endpoints
+
[source,console]
----
$ kubectl get endpoints --all-namespaces
NAMESPACE        NAME                   ENDPOINTS                                               AGE
default          go-hello-pod-metallb   <none>                                                  5m36s
default          kubernetes             172.18.0.2:6443                                         37m
kube-system      kube-dns               10.244.0.2:53,10.244.0.3:53,10.244.0.2:53 + 3 more...   37m
metallb-system   webhook-service        10.244.0.5:9443                                         36m
----

* Get endpoints
+
[source,console]
----
kubectl get endpoints go-hello-service -o json
----
+
[source,json]
----
{
    "apiVersion": "v1",
    "kind": "Endpoints",
    "metadata": {
        "annotations": {
            "endpoints.kubernetes.io/last-change-trigger-time": "2022-08-27T23:57:09Z"
        },
        "creationTimestamp": "2022-08-27T23:57:07Z",
        "name": "go-hello-service",
        "namespace": "default",
        "resourceVersion": "14624",
        "uid": "9dbcd5ca-abd8-46a5-9ebd-aa91f7c99b59"
    },
    "subsets": [
        {
            "addresses": [
                {
                    "ip": "10.244.0.8",
                    "nodeName": "kind-1-control-plane",
                    "targetRef": {
                        "kind": "Pod",
                        "name": "go-hello-app-6cf496f84c-bq4rp",
                        "namespace": "default",
                        "uid": "16eb41f9-6f72-4438-ba0a-32cb83c603d5"
                    }
                }
            ],
            "ports": [
                {
                    "name": "http",
                    "port": 8080,
                    "protocol": "TCP"
                }
            ]
        }
    ]
}
----

* Describe endpoints
+
[source,console]
----
$ kubectl describe endpoints go-hello-service
Name:         go-hello-service
Namespace:    default
Labels:       <none>
Annotations:  endpoints.kubernetes.io/last-change-trigger-time: 2022-08-27T23:57:09Z
Subsets:
  Addresses:          10.244.0.8
  NotReadyAddresses:  <none>
  Ports:
    Name  Port  Protocol
    ----  ----  --------
    http  8080  TCP

Events:  <none>
----

=== Storage

==== emptyDir

// include::../kind/ex-storage-empty-dir.yaml[]
[source,yaml]
.kind/ex-storage-empty-dir.yaml
----
apiVersion: v1
kind: Pod
metadata:
  name: ex-storage-empty-dir
spec:
  containers:
  - image: nginx:1.23
    name: nginx-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir: {}
----

[source,shell]
----
kubectl apply -f kind/ex-storage-empty-dir.yaml
----

[source,console]
----
$ kubectl exec -it ex-storage-empty-dir -- df -h /cache
Filesystem      Size  Used Avail Use% Mounted on
/dev/sdb        251G   17G  222G   8% /cache
----

==== Persistent Volume

[source,yaml]
----
apiVersion: v1
kind: PersistentVolume
metadata:
  name: ${PV_NAME}
spec:
  capacity:
    storage: 256Mi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: ""
  local:
    path: ${MOUNT_POINT}
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
            - ${KUBE_HOSTNAME}
----

// include::../kind/ex-storage-pv-local/ex-storage-pv-local-pod.yaml[]
[source,yaml]
.ex-storage-pv-local-pod.yaml
----
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: local-claim
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 128Mi
  storageClassName: ""
  volumeName: "ex-storage-pv"
  accessModes:
    - ReadWriteOnce
---
apiVersion: v1
kind: Pod
metadata:
  name: ex-storage-pv-local-pod
spec:
  nodeName: kind-1-control-plane
  containers:
  - image: nginx:1.23
    name: nginx-container
    imagePullPolicy: IfNotPresent
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    persistentVolumeClaim:
      claimName: local-claim
----

. Make directory (KIND only)
+
[source,shell]
----
docker exec ${KUBE_NODENAME} mkdir -p ${MOUNT_POINT}
----

. Deploy
+
[source,shell]
----
kubectl apply -f ${WORK_DIR}/ex-storage-pv-local.yaml
kubectl apply -f ex-storage-pv-local-pod.yaml
----

. Delete
+
[source,shell]
----
kubectl delete -f ex-storage-pv-local-pod.yaml
kubectl delete persistentvolume ${PV_NAME}
----

. Delete directory (KIND only)
+
[source,shell]
----
docker exec ${KUBE_NODENAME} rmdir ${MOUNT_POINT}
----

=== Get information

* Listing all resources in a namespace
+
[source,shell]
----
kubectl api-resources --verbs=list --namespaced -o name | python3 -c "import subprocess, sys; subprocess.run(['kubectl', 'get', '-n', '${NAMESPACE}', ','.join([x for x in sys.stdin.read().split() if x not in ['events.events.k8s.io', 'events']])])"
----
+
[source,shell]
----
kubectl api-resources --verbs=list --namespaced -o name | grep -vE '^(events|events\.events\.k8s\.io)$' | tr "\n" "," | sed -e 's/,$//' | xargs kubectl get -n "${NAMESPACE}"
----

=== Troubleshooting

* ip route
+
[source,console]
----
$ ip route
default via 172.31.160.1 dev eth0
172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
172.18.0.0/16 dev br-cb34625844b6 proto kernel scope link src 172.18.0.1
172.31.160.0/20 dev eth0 proto kernel scope link src 172.31.169.105
----

** Show a specific route
+
[source,console]
----
$ ip route list 172.18.0.0/16
172.18.0.0/16 dev br-cb34625844b6 proto kernel scope link src 172.18.0.1
----

* arp +
Service に対する Endpoint が作成されていない場合は、 `HWaddress` の項目は `(incomplete)` になる
+
[source,console]
----
$ arp
Address                  HWtype  HWaddress           Flags Mask            Iface
172.18.0.2               ether   02:42:ac:12:00:02   C                     br-cb34625844b6
DESKTOP-E39V4F4          ether   00:15:5d:31:24:02   C                     eth0
172.18.254.240                   (incomplete)                              br-cb34625844b6
----

* arping
+
[source,console]
----
$ sudo arping 172.18.254.240 -c 3
ARPING 172.18.254.240
Timeout
Timeout
Timeout

--- 172.18.254.240 statistics ---
3 packets transmitted, 0 packets received, 100% unanswered (0 extra)
----

* Find ip
+
[source,console]
----
$ kubectl get services --all-namespaces | grep 172.18.254
default          go-hello-pod-metallb   LoadBalancer   10.96.17.114    172.18.254.240   8080:30161/TCP           22m
----

=== Auth

[source,shell]
----
kubectl auth can-i list pods
----

=== API

* List API resources
+
[source,shell]
----
kubectl api-resources
----

* Get API Server URI
+
[source,shell]
----
kubectl config view -o jsonpath='{.clusters[0].cluster.server}'
----

* Get version
+
[source,shell]
----
curl --insecure $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/version
----

* Using client certificate
+
[source,shell]
----
kubectl config view --minify --raw -o jsonpath='{.users[].user.client-certificate-data}' | base64 --decode > client.crt
kubectl config view --minify --raw -o jsonpath='{.users[].user.client-key-data}' | base64 --decode > client.key
----

** List apis
+
[source,shell]
----
curl --insecure --cert ./client.crt --key ./client.key $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/apis
----

** List pod name
+
[source,shell]
----
curl -s --insecure --cert ./client.crt --key ./client.key $(kubectl config view -o jsonpath='{.clusters[0].cluster.server}')/api/v1/namespaces/rbac-demo/pods | jq -r '.items[] | .metadata.name'
----

== Service Binding

.Setup Service Binding
. Install `cert-manager`
+
[source,shell]
----
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.11.0/cert-manager.yaml
----
+
.References
* https://cert-manager.io/docs/installation/[Installation - cert-manager Documentation^]

. To install the Service Binding Runtime with kubectl, run:
+
[source,shell]
----
kubectl apply -f https://github.com/servicebinding/runtime/releases/download/v0.3.0/servicebinding-runtime-v0.3.0.yaml
----
+
.References
* https://github.com/servicebinding/runtime/releases[Releases · servicebinding/runtime^]

.References
* https://github.com/spring-cloud/spring-cloud-bindings[spring-cloud/spring-cloud-bindings^] +
  A library that exposes a rich Java language-binding and auto-configuration for CNB Bindings

== krew

=== Install krew

https://krew.sigs.k8s.io/docs/user-guide/setup/install/[Installing · Krew^]

.Install
. Run this command to download and install krew:
+
[source,shell]
----
(
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
----

. Add the $HOME/.krew/bin directory to your PATH environment variable.
+
[source,shell]
.~/.bashrc
----
test -d ${KREW_ROOT:-$HOME/.krew} && export PATH="${KREW_ROOT:-$HOME/.krew}/bin:$PATH"
----

. Run kubectl krew to check the installation.
+
[source,shell]
----
kubectl krew version
----

. Install plug-ins
+
[source,shell]
----
kubectl krew install neat
----

== Tekton

* https://buildpacks.io/docs/tools/tekton/[Tekton · Cloud Native Buildpacks^]

== Knative

* https://qiita.com/t_okkan/items/eef036534ce3d5511df6[Knative Servingでサーバーレスを始める - Qiita^] +
  Knative - Search

== References
